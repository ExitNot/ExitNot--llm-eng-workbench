{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c53f32",
   "metadata": {},
   "source": [
    "# AI-Powered Code Generation: Python to C++ Optimization\n",
    "\n",
    "## üìã Overview\n",
    "This notebook explores the capabilities of state-of-the-art LLMs for **automated code generation**, specifically focusing on converting Python code to high-performance C++ implementations just in a metter of experiment during completing the [course](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/?couponCode=MT250923G1).\n",
    "\n",
    "## üéØ Objectives\n",
    "- **Performance Benchmarking**: Compare execution speed improvements between Python and AI-generated C++ code\n",
    "- **Model Evaluation**: Test and compare different LLMs' code generation capabilities\n",
    "- **Pipeline Development**: Build an automated conversion pipeline for production use\n",
    "\n",
    "## üî¨ Methodology\n",
    "We'll evaluate models using:\n",
    "1. **Computational Tasks**: Mathematical algorithms (œÄ computation, array processing)\n",
    "2. **Performance Metrics**: Execution time comparison and correctness validation  \n",
    "3. **Code Quality**: Analyzing generated C++ code structure and optimization techniques\n",
    "\n",
    "## üí° Expected Outcomes\n",
    "- Identify the best-performing LLM for code generation tasks\n",
    "- Quantify performance improvements (targeting 10x+ speedup)\n",
    "- Establish a reliable conversion pipeline for Python ‚Üí C++ optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40fae9",
   "metadata": {},
   "source": [
    "## üîç Model Selection & Evaluation Framework\n",
    "\n",
    "### üìä Industry Benchmarking Sources\n",
    "To select optimal models for our code generation task, we analyze current industry leaderboards:\n",
    "\n",
    "| **Leaderboard** | **Focus Area** | **Key Metrics** |\n",
    "|-----------------|----------------|-----------------|\n",
    "| [Vellum AI Coding](https://www.vellum.ai/best-llm-for-coding) | General coding tasks | Multi-language performance |\n",
    "| [SEAL Leaderboard](https://scale.com/leaderboard/coding) | Software engineering | Real-world problem solving |\n",
    "\n",
    "### üß™ Understanding Coding Benchmarks\n",
    "\n",
    "Modern LLM evaluation relies on several standardized benchmarks, each testing different aspects of coding capability:\n",
    "\n",
    "#### **üéØ Core Benchmarks**\n",
    "\n",
    "| **Benchmark** | **Problems** | **Focus** | **Difficulty** |\n",
    "|---------------|-------------|-----------|----------------|\n",
    "| **HumanEval** | 164 Python problems | Language comprehension, algorithms, mathematics | Entry to intermediate |\n",
    "| **MBPP** | 974 programming tasks | Natural language ‚Üí code synthesis | Entry level |\n",
    "| **SWE-Bench** | Real GitHub issues | Production code debugging & enhancement | Advanced |\n",
    "| **LiveCodeBench** | Contest problems (LeetCode, AtCoder, CodeForces) | Competitive programming, self-repair, execution | Advanced |\n",
    "\n",
    "#### **üî¨ Why These Benchmarks Matter for Our Task**\n",
    "- **HumanEval**: Tests fundamental algorithmic thinking crucial for optimization tasks\n",
    "- **SWE-Bench**: Evaluates real-world code manipulation skills needed for language conversion\n",
    "- **LiveCodeBench**: Ensures models can handle complex computational problems like our test cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eecfc39",
   "metadata": {},
   "source": [
    "### üéØ Model Selection Strategy\n",
    "\n",
    "For this experiment, we focus on **high-performance models accessible through free tiers** to ensure reproducibility and cost-effectiveness.\n",
    "\n",
    "#### **üèÜ Selected Models**\n",
    "\n",
    "Based on [LLM Stats HumanEval Leaderboard](https://llm-stats.com/benchmarks/humaneval), our candidates are:\n",
    "\n",
    "| **Model** | **Parameters** | **HumanEval** | **SWE-Bench** | **Availability** | **Expected Performance** |\n",
    "|-----------|----------------|---------------|----------------|------------------|-------------------------|\n",
    "| **Kimi Dev 72B** | 72B | ~85% | 60.4% | OpenRouter Free | Strong mathematical reasoning |\n",
    "| **Qwen3 Coder 480B** | 480B (A35B active) | ~90% | 69.6% | OpenRouter Free | Superior code generation |\n",
    "\n",
    "#### **üîÆ Performance Hypothesis**\n",
    "- **Qwen3 Coder**: Expected to excel due to specialized training on code and larger active parameter count\n",
    "- **Kimi Dev**: Strong mathematical foundation may benefit algorithmic tasks\n",
    "- **Key Test**: Which model produces more optimized C++ code with better performance characteristics?\n",
    "\n",
    "#### **‚öñÔ∏è Evaluation Criteria**\n",
    "1. **Correctness**: Identical output to Python implementation\n",
    "2. **Performance**: Execution speed improvement\n",
    "3. **Code Quality**: C++ best practices and optimization techniques\n",
    "4. **Generation Speed**: Model response time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "MODEL_KIMI_K2 = \"moonshotai/kimi-dev-72b:free\"\n",
    "MODEL_QWEN_3_CODER = \"qwen/qwen3-coder:free\"\n",
    "MODEL_GEMINI_2_FLASH = \"google/gemini-2.5-flash:free\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce92e2a",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38d6479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import enum\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c60fa321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouter API key is set\n",
      "Google API key is set\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "open_router_api_key = os.getenv('OPEN_ROUTER_API_KEY', 'NO_OPEN_ROUTER_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY', 'NO_GOOGLE_API_KEY')\n",
    "\n",
    "if open_router_api_key == 'NO_OPEN_ROUTER_API_KEY':\n",
    "    raise ValueError('Please set OPEN_ROUTER_API_KEY in your environment variables')\n",
    "else:\n",
    "    print('OpenRouter API key is set')\n",
    "\n",
    "if google_api_key == 'NO_GOOGLE_API_KEY':\n",
    "    raise ValueError('Please set GOOGLE_API_KEY in your environment variables')\n",
    "else:\n",
    "    print('Google API key is set')\n",
    "\n",
    "OPEN_ROUTER_API_URL = \"https://openrouter.ai/api/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenRouter client\n",
    "or_client = OpenAI(base_url=OPEN_ROUTER_API_URL, api_key=open_router_api_key)\n",
    "\n",
    "google_client = genai.Client(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b834a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an assistant that reimplements Python code in high performance C++ for an M1 Mac. \n",
    "Respond only with C++ code; use comments sparingly and do not provide any explanation other than occasional comments. \n",
    "The C++ response needs to produce an identical output in the fastest possible time.\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python_code: str) -> str:\n",
    "    # remember to #include is not needed for Claude but needed for GPT. Let's test with it for now covering more models and cases.\n",
    "    user_prompt = \"\"\"\n",
    "    Rewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time. \n",
    "    Respond only with C++ code; do not explain your work other than a few comments. \n",
    "    Pay attention to number types to ensure no int overflows. Remember to #include all necessary C++ packages such as iomanip.\n",
    "\n",
    "    Response should be only C++ code\n",
    "\n",
    "    Python code:\n",
    "    \"\"\"\n",
    "    user_prompt += python_code\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(python_code: str) -> list[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python_code)}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b76cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a file called optimized.cpp\n",
    "\n",
    "def clean_think_blocks(text):\n",
    "    \"\"\"Remove content between <think>...</think> or ‚óÅthink‚ñ∑... markers\"\"\"\n",
    "    # Remove <think>...</think> blocks\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    # Remove ‚óÅthink‚ñ∑...‚óÅthink‚ñ∑ blocks for Kimi model\n",
    "    text = re.sub(r'‚óÅthink‚ñ∑.*?‚óÅ/think‚ñ∑\\n\\n', '', text, flags=re.DOTALL)\n",
    "     \n",
    "    return text\n",
    "\n",
    "def write_output(cpp_code: str, file_name: str = \"optimized.cpp\"):\n",
    "    code = clean_think_blocks(cpp_code)\n",
    "    code = code.replace(\"```cpp\",\"\").replace(\"```\",\"\")\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_kimi(python_code: str):    \n",
    "    stream = or_client.chat.completions.create(model=MODEL_KIMI_K2, messages=messages_for(python_code), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        print(fragment, end='', flush=True)\n",
    "    write_output(reply, file_name=\"optimized_kimi.cpp\")\n",
    "\n",
    "def optimize_qwen(python_code: str):\n",
    "    stream = or_client.chat.completions.create(model=MODEL_QWEN_3_CODER, messages=messages_for(python_code), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        print(fragment, end='', flush=True)\n",
    "    write_output(reply, file_name=\"optimized_qwen.cpp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904df0d",
   "metadata": {},
   "source": [
    "## üßÆ Experiment 1: Pi Computation via Riemann Sum\n",
    "\n",
    "### üìù Task Description\n",
    "**Objective**: Convert a Python œÄ computation algorithm to optimized C++ code\n",
    "\n",
    "**Algorithm**: Riemann sum approximation using the integral formula:\n",
    "```\n",
    "œÄ = 4 ‚à´‚ÇÄ¬π 1/(1+x¬≤) dx\n",
    "```\n",
    "\n",
    "### üîç Why This Test Case?\n",
    "- **Mathematical Foundation**: Tests models' understanding of numerical computation\n",
    "- **Loop Optimization**: Critical for performance - models must optimize the 100M iteration loop\n",
    "- **Precision Handling**: Requires careful floating-point arithmetic\n",
    "- **Common Benchmark**: Widely used in performance testing, enabling comparison with established baselines\n",
    "\n",
    "### üìä Success Metrics\n",
    "- ‚úÖ **Correctness**: Result matches Python output (3.141592653590)\n",
    "- ‚ö° **Performance**: Target >50x speedup over Python\n",
    "- üîß **Code Quality**: Proper C++ optimization techniques (compiler flags, data types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daff5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def integrate_pi(iterations: int) -> float:\n",
    "    step = 1.0 / iterations\n",
    "    total = 0.0\n",
    "    for i in range(iterations):\n",
    "        x = (i + 0.5) * step\n",
    "        total += 4.0 / (1.0 + x*x)\n",
    "    return step * total\n",
    "\n",
    "start_time = time.time()\n",
    "result = integrate_pi(100_000_000)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3daa3902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592653590\n",
      "Execution Time: 7.109315 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f47f2c",
   "metadata": {},
   "source": [
    "Now we ready to TRY!!!\n",
    "\n",
    "Let's start from Kimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4e371bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚óÅthink‚ñ∑Okay, let's tackle this problem. The user wants to rewrite the given Python code into C++ with the fastest possible implementation. The goal is to produce the same output but in record time. Let me think about how to approach this.\n",
      "\n",
      "First, the Python function integrate_pi calculates an approximation of pi using the Monte Carlo method. The user provided code uses a loop that runs for a specified number of iterations (like 100 million). The main aspect here is the loop, which adds up the terms of the series. Converting this to C++ requires translating that loop and ensuring that the number types are appropriate to prevent integer overflow, which the user specifically mentioned.\n",
      "\n",
      "Looking at the Python code: the step is 1.0 divided by iterations. Then, for each i from 0 to iterations-1, x is (i + 0.5) * step, and then total accumulates 4.0 divided by (1.0 + x*x). Finally, the result is step multiplied by the total sum.\n",
      "\n",
      "In C++, we need to replicate this. The range function in Python is a loop from 0 to iterations-1. In C++, that would be a for loop from i=0; i<iterations; i++. \n",
      "\n",
      "The data types here are important. The Python code uses float values. So in C++, we should use double for precision. Also, the iterations parameter is an int, but for very large numbers (like 1e8), but since in C++ int types are typically 32-bit, but using unsigned long long might be better to handle larger values. Wait, but the original Python code has iterations as an int. The C++ code would need to use a type that can handle the same number of iterations. Let me check: the input given in the Python example is 100_000_000, which is 1e8. That's well within a 32-bit integer's range (since 2^31 is about 2.1e9). So using int in C++ should be safe here. Wait, but in C++, int can vary. On a Mac with x86, int is 32-bit. But what about the M1 architecture? The M1 uses ARM64, where int is still 32-bit, but perhaps using long long might be safer. However, the user's original code in Python uses int, and the C++ code should mirror that. The problem statement mentions to ensure no int overflows. So perhaps we should use longer integer types. Wait, the iterations parameter is passed as an int to integrate_pi. But when multiplying by step in each loop iteration, if the loop variable i is an int, then for i up to 1e8, adding 0.5 would still be handled as a floating-point operation. But to prevent integer overflow, maybe the loop variable should be an unsigned integer. However, in the code, the loop runs 'iterations' times. So if we use a 32-bit int for iterations, the loop variable i can safely reach up to 1e8. So perhaps using int is fine here. \n",
      "\n",
      "But in the calculation of x, which is (i + 0.5) * step. Since i is an integer, adding 0.5 would convert it to a double. So in C++, we need to make sure that all arithmetic is done in double precision. So the loop variable i should be an integer type, but when calculating x, it's cast to a double. \n",
      "\n",
      "Let me structure the C++ code. The main function will be similar. Let me start with the includes. The Python code uses time.time(), so in C++, we need to time the function. The C++ standard library has the <chrono> header for timing. But maybe using <ctime> would be more straightforward. Alternatively, perhaps <sys/time.h> but that's platform-specific. Since the user is on M1 Mac, which uses macOS, perhaps the best approach is to use std::chrono::high_resolution_clock.\n",
      "\n",
      "Wait, but in the Python code, time.time() is called before and after the function to get the elapsed time. In C++, using std::chrono::high_resolution_clock::now() would be the way to go. Let me outline the steps.\n",
      "\n",
      "The C++ function integrate_pi would take an integer (or maybe unsigned int) iterations, and return a double. \n",
      "\n",
      "The loop would be:\n",
      "\n",
      "double step = 1.0 / iterations;\n",
      "double total = 0.0;\n",
      "for (int i = 0; i < iterations; i++) {\n",
      "    double x = (i + 0.5) * step;\n",
      "    total += 4.0 / (1.0 + x * x);\n",
      "}\n",
      "return step * total;\n",
      "\n",
      "But in C++, using integers for loop variables. But given the number of iterations (1e8), we need to ensure that the loop variable i doesn't overflow. For example, if iterations is 1e9, but for this code, it's 1e8. So using an int is safe. \n",
      "\n",
      "But to be safe, maybe use unsigned int. However, the step is 1.0 divided by iterations, which is okay as long as iterations is positive. But the original Python code doesn't handle negative iterations. So assuming iterations is always positive. \n",
      "\n",
      "So translating that into C++ code. \n",
      "\n",
      "Now, C++ has some optimizations. Let me think about optimizing the loop. For example, precomputing some intermediate variables, or unrolling the loop. \n",
      "\n",
      "In the loop, each iteration does:\n",
      "\n",
      "x = (i + 0.5) * step\n",
      "term = 4.0 / (1 + x*x)\n",
      "total += term\n",
      "\n",
      "We can simplify x:\n",
      "\n",
      "x = (i + 0.5) * step\n",
      "Since step is 1.0 / iterations, then x can be written as (i + 0.5) / iterations.\n",
      "\n",
      "But that doesn't help the computation. The calculation of x each time seems necessary.\n",
      "\n",
      "Another approach: Parallelization. However, the user is using an M1 Mac, which has ARM architecture. OpenMP is supported in some compilers (like Clang with OpenMP library). However, the user might not have that set up. But since the problem states to generate C++ code, maybe assuming that the code will be compiled with OpenMP or similar. But if not, parallelizing might not be possible. However, given the problem's constraints, the user's goal is the fastest possible time. So parallelizing the loop would be beneficial.\n",
      "\n",
      "But how to do that in C++ without assuming external libraries? If the user is allowed to use OpenMP, then adding #pragma omp parallel for could help. However, the user's original code in Python is single-threaded. But the code could be modified to use multiple threads. However, the user might not have that in mind. But the problem says to reimplement for speed. So perhaps adding parallelism would be valid.\n",
      "\n",
      "But since the user didn't mention parallelization, maybe the code should be single-threaded. However, in C++, the same loop can be written with better optimization. For example, using floating-point variables more efficiently.\n",
      "\n",
      "Another consideration: Data type precision. Using long double instead of double for higher precision. But the Python code uses float (since 4.0 is a float), but in Python, float is 64-bit (double). So in C++, we should use double for precision and speed. Using double is usually faster than long double, and gives better precision.\n",
      "\n",
      "So the plan is to write a C++ function that mirrors the Python code but uses C++ semantics and tries to optimize the loop.\n",
      "\n",
      "Now, let's think about the C++ code structure.\n",
      "\n",
      "First, include necessary headers.\n",
      "\n",
      "- iostream for output\n",
      "- time.h for timing (or chrono)\n",
      "- iomanip for formatting floats (like fixed, setprecision)\n",
      "\n",
      "Wait, the Python code uses print(f\"Result: {result:.12f}\"). In C++, using std::fixed and std::setprecision(12). So we need to include <iomanip>.\n",
      "\n",
      "Also, for timing, the Python uses time.time(), which is in seconds. In C++, using std::chrono::high_resolution_clock to get the time before and after the function.\n",
      "\n",
      "But the code should be compatible with macOS M1, which uses the Apple Clang compiler. So using standard C++ libraries.\n",
      "\n",
      "Putting it all together:\n",
      "\n",
      "The C++ code would have:\n",
      "\n",
      "#include <iostream>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "double integrate_pi(int iterations) {\n",
      "    double step = 1.0 / iterations;\n",
      "    double total = 0.0;\n",
      "    for (int i = 0; i < iterations; i++) {\n",
      "        double x = (i + 0.5) * step;\n",
      "        total += 4.0 / (1.0 + x * x);\n",
      "    }\n",
      "    return step * total;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start = std::chrono::high_resolution_clock::now();\n",
      "    double result = integrate_pi(100'000'000);\n",
      "    auto end = std::chrono::high_resolution_clock::now();\n",
      "\n",
      "    std::chrono::duration<double> elapsed = end - start;\n",
      "\n",
      "    // Set precision for result and time\n",
      "    std::cout << std::fixed << std::setprecision(12);\n",
      "    std::cout << \"Result: \" << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "Wait, but the Python code uses 100_000_000, which in C++ can be written as 100'000'000 (with apostrophes as thousand separators, which C++14+ supports). The user's code may use a compiler that supports that? But perhaps the apostrophes are allowed. Alternatively, without them, like 100000000.\n",
      "\n",
      "So in the code, the number is 100'000'000, which is 100 million. But C++ requires that the code uses correct syntax. The apostrophes in integer literals are allowed in C++14 and later. So assuming the user has a modern compiler, that's fine.\n",
      "\n",
      "But if the user's compiler doesn't support it, then the code should use 100000000. But the problem states to write the code to run on M1 Mac, which likely uses the latest Xcode, which has Clang supporting C++14.\n",
      "\n",
      "Now, testing the code. The integrate part. \n",
      "\n",
      "In the Python code, the loop variable i ranges from 0 to iterations-1. In the C++ code, the for loop is correctly written as for(int i=0; i < iterations; i++).\n",
      "\n",
      "But let's check the calculation:\n",
      "\n",
      "In Python:\n",
      "\n",
      "x = (i + 0.5) * step\n",
      "\n",
      "In C++:\n",
      "\n",
      "double x = (i + 0.5) * step;\n",
      "\n",
      "Same. Then, the term is 4.0 divided by (1.0 + x*x). \n",
      "\n",
      "But in the C++ code, the term is 4.0/(1.0 + x*x). Which is correct. \n",
      "\n",
      "So the code should produce the same result. \n",
      "\n",
      "But wait, in Python, all numbers are stored as double precision. In C++, we are using double, so the same. So the integration should be correct.\n",
      "\n",
      "But the performance difference can come from the loop overhead. In Python, loops are slower because it's an interpreted language. C++ is compiled, so the loop runs much faster. \n",
      "\n",
      "But the user's code is written in Python and they want to convert it to C++ for speed. \n",
      "\n",
      "But wait, the Python code uses the code point 100_000_000. In the example, the code runs integrate_pi with 100 million iterations. That's a lot. In Python, that's a huge loop. In C++, this loop should execute much faster.\n",
      "\n",
      "But the code could be further optimized. For example, precalculating some values. Let's look at x:\n",
      "\n",
      "x = (i + 0.5) * step = (i * step) + (0.5 * step)\n",
      "\n",
      "But step is 1/iterations. So x can be written as (i + 0.5)/iterations. But that doesn't help the computation. \n",
      "\n",
      "Another optimization: loop unrolling. For example, process multiple iterations per loop iteration. But that's more complex and might not help unless the loop is doing a lot of work. \n",
      "\n",
      "Alternatively, using inline assembly or other low-level optimizations. But perhaps using compiler flags like -O3 would handle some optimizations automatically. However, the user is to provide the C++ code, not the build commands. \n",
      "\n",
      "The problem states to generate C++ code that produces identical output in the least time. So using all possible optimizations within the code. But perhaps the code as written is already optimal for such a loop.\n",
      "\n",
      "Another possibility: using floating-point variables instead of integers for the loop, but that's not safe. \n",
      "\n",
      "Wait, but in the loop:\n",
      "\n",
      "for (int i = 0; i < iterations; i++) {\n",
      "    double x = (i + 0.5) * step;\n",
      "    total += 4.0 / (1.0 + x * x);\n",
      "}\n",
      "\n",
      "Since 'i' is an integer, adding 0.5 converts it to a double. So the calculation is in double-precision. Which is correct. \n",
      "\n",
      "So the code should be correct and fast. \n",
      "\n",
      "Now, the output formatting. The Python code uses:\n",
      "\n",
      "print(f\"Result: {result:.12f}\")\n",
      "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
      "\n",
      "In C++, we need to set the precision for the result to 12 decimal places and the time to 6 decimal places. \n",
      "\n",
      "The code uses:\n",
      "\n",
      "std::cout << std::fixed << std::setprecision(12);\n",
      "std::cout << \"Result: \" << result << std::endl;\n",
      "std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "But wait, the 'elapsed.count()' returns a double representing seconds. So setting the precision to 6 for that output. \n",
      "\n",
      "But in the code, after printing the result with 12 digits, the next line uses another precision. So perhaps we need to reset the precision. Or combine into a single stream:\n",
      "\n",
      "std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
      "std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "Wait, the 'std::fixed' and 'std::setprecision' are manipulators. Once set, they affect all subsequent outputs. But in the code above, the first line sets precision to 12, then the second line would use the same precision. So that's not correct. The time needs 6 decimal places. So maybe:\n",
      "\n",
      "std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
      "std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "But the first time we set precision to 12, and then for the second line, set it to 6. But how does that work in the code? The code as written sets precision once. So for the result, the code would need to set precision to 12, then for the time, set it to 6. \n",
      "\n",
      "So the correct approach is to set precision individually for each output. For example:\n",
      "\n",
      "std::cout << std::fixed << std::setprecision(12) << \"Result: \" << result << std::endl;\n",
      "std::cout << std::fixed << std::setprecision(6) << \"Execution Time: \" << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "Wait, no. The 'std::setprecision' affects the subsequent floating-point numbers in the output. So:\n",
      "\n",
      "std::cout << std::fixed << std::setprecision(12) << \"Result: \" << result << std::endl;\n",
      "std::cout << std::fixed << std::setprecision(6) << \"Execution Time: \" << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "But the first line sets the precision to 12, which applies to 'result', and the second line sets it to 6 for 'elapsed.count()'. But the strings and other non-floating point parts are not affected. \n",
      "\n",
      "But the code in the original answer has:\n",
      "\n",
      "std::cout << \"Result: \" << result << std::endl;\n",
      "std::cout << \"Execution Time: \" << ... << std::endl;\n",
      "\n",
      "So, perhaps adding the manipulators before each floating-point number. So:\n",
      "\n",
      "std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
      "std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "But wait, the order matters. The 'std::fixed' and 'std::setprecision' set the format flags for the next outputs. So the first line sets fixed and precision to 12, then prints the result. Then, the second line sets fixed and precision to 6, then prints the elapsed time. \n",
      "\n",
      "This way, each line has the correct precision. \n",
      "\n",
      "So that's correct. \n",
      "\n",
      "So the final C++ code would look like:\n",
      "\n",
      "#include <iostream>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "double integrate_pi(int iterations) {\n",
      "    double step = 1.0 / iterations;\n",
      "    double total = 0.0;\n",
      "    for (int i = 0; i < iterations; i++) {\n",
      "        double x = (i + 0.5) * step;\n",
      "        total += 4.0 / (1.0 + x * x);\n",
      "    }\n",
      "    return step * total;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start = std::chrono::high_resolution_clock::now();\n",
      "    double result = integrate_pi(100'000'000);\n",
      "    auto end = std::chrono::high_resolution_clock::now();\n",
      "\n",
      "    std::chrono::duration<double> elapsed = end - start;\n",
      "\n",
      "    std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "But wait, the code in the original answer was written as:\n",
      "\n",
      "    std::chrono::duration<double> elapsed = end - start;\n",
      "\n",
      "But 'end' and 'start' are std::chrono::time_point objects. The difference is a std::chrono::duration, and when you assign it to 'std::chrono::duration<double>', that's correct.\n",
      "\n",
      "But 'elapsed.count()' returns the duration as a double (the number of seconds).\n",
      "\n",
      "So the code should be correct. \n",
      "\n",
      "Now, testing this code should output the same result as the Python code. However, floating-point precision may vary between Python and C++. But since both are using 64-bit floating points, the results should be close, but not exactly the same. However, the problem states that the output must be identical. Wait, but the user wrote: \"the C++ response needs to produce an identical output in the fastest possible time.\" So the output must match exactly what Python produces. But due to floating-point differences, this is difficult. However, the user might have allowed for small differences, but the code should at least format the output in the same way. \n",
      "\n",
      "But the user's example uses 100_000_000 iterations. Let's see: the actual value of pi is about 3.141592653589793, and the Python code with 1e8 iterations may produce a value that's close but not exact. The C++ code using the same algorithm would produce a similar result, but due to different floating-point rounding, the exact decimal digits may differ. However, the user's problem is about reimplementing the code in C++, not necessarily getting bit-for-bit identical results. But the user states \"produces identical output\", which is challenging. \n",
      "\n",
      "But given that Python and C++ may have different floating-point implementations, getting the exact same digits is difficult. But perhaps with careful handling, it's possible. However, this may require more in-depth analysis. \n",
      "\n",
      "But the problem's main goal is to rewrite the code in C++ for speed. So even if the digits are slightly different due to rounding, as long as the code is correct in structure and produces a similar result, the performance improvement is the key. \n",
      "\n",
      "Thus, the code should be correct structurally. \n",
      "\n",
      "Another thing: The loop's iteration count. In Python, the range function goes up to iterations-1. In C++, the for loop does the same. \n",
      "\n",
      "But what about the type of 'iterations'? In Python, it's an integer, but in C++, if we pass a value larger than what can fit in an int, but in Python, it's an arbitrary-precision integer. However, the user's example uses 100,000,000 which is well within 32-bit integer range. So using int in C++ is safe. \n",
      "\n",
      "But for safety, perhaps the function should take a std::size_t or unsigned long long. But the problem statement's Python code uses 'iterations: int', so we should match that. But in C++, using 'int' for the parameter. But for large values, if the code is called with a very large number, the C++ code's int may overflow. But according to the problem statement, the user is to pay attention to number types to avoid overflow. So perhaps using a larger integer type.\n",
      "\n",
      "But for the given example of 1e8, using int is safe. \n",
      "\n",
      "But to be safe, perhaps the function should take a std::int64_t, but that might not be necessary. \n",
      "\n",
      "Alternatively, in the loop, the loop variable 'i' could be of type 'unsigned int' or 'long' to prevent overflow. But since step is 1.0 divided by iterations, if iterations is 0, that's a problem. But the user would have handled that. \n",
      "\n",
      "But given the problem's parameters, the code as written should be correct.\n",
      "\n",
      "Now, let's check the code for possible optimizations. \n",
      "\n",
      "The calculation of 'x' can be simplified. Let's look at:\n",
      "\n",
      "x = (i + 0.5) * step = i * step + 0.5 * step\n",
      "\n",
      "But step is 1.0 / iterations. So 0.5 * step is 0.5/iterations. But that's a constant. \n",
      "\n",
      "But this may not lead to a significant improvement. \n",
      "\n",
      "Another approach is to reuse the x value. \n",
      "\n",
      "But the main issue is the loop's time. In C++, the loop should be optimized. \n",
      "\n",
      "So the code as written is correct and should be fast. \n",
      "\n",
      "Now, the user's code uses 'print' in Python, which outputs to stdout. The C++ code uses std::cout. \n",
      "\n",
      "But on macOS, the output format may be different, but given the use of fixed and setprecision, the formatting should be equivalent. \n",
      "\n",
      "Thus, the final C++ code would be as outlined above.\n",
      "‚óÅ/think‚ñ∑\n",
      "\n",
      "```cpp\n",
      "#include <iostream>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "double integrate_pi(int iterations) {\n",
      "    double step = 1.0 / iterations;\n",
      "    double total = 0.0;\n",
      "    for (int i = 0; i < iterations; i++) {\n",
      "        double x = (i + 0.5) * step;\n",
      "        total += 4.0 / (1.0 + x * x);\n",
      "    }\n",
      "    return step * total;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start = std::chrono::high_resolution_clock::now();\n",
      "    double result = integrate_pi(100'000'000);\n",
      "    auto end = std::chrono::high_resolution_clock::now();\n",
      "\n",
      "    std::chrono::duration<double> elapsed = end - start;\n",
      "\n",
      "    std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "This C++ implementation:\n",
      "1. Uses the same numerical algorithm as the Python code to ensure identical results\n",
      "2. Leverages C++'s efficient looping and arithmetic for faster execution\n",
      "3. Templates the timing using high_resolution_clock for precise measurements\n",
      "4. Formats the output to exactly match Python's formatting with fixed-precision decimals\n",
      "5. Uses proper C++ type handling to prevent integer overflow by keeping iterations as a 32-bit integer (which is safe for 100 million iterations)"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'write_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimize_kimi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36moptimize_kimi\u001b[0;34m(python_code)\u001b[0m\n\u001b[1;32m      6\u001b[0m     reply \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fragment\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(fragment, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwrite_output\u001b[49m(reply)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_output' is not defined"
     ]
    }
   ],
   "source": [
    "optimize_kimi(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6f11c",
   "metadata": {},
   "source": [
    "First try failed to write the result, but here is the actual result:\n",
    "\n",
    "```\n",
    "#include <iostream>\n",
    "#include <chrono>\n",
    "#include <iomanip>\n",
    "\n",
    "double integrate_pi(int iterations) {\n",
    "    double step = 1.0 / iterations;\n",
    "    double total = 0.0;\n",
    "    for (int i = 0; i < iterations; i++) {\n",
    "        double x = (i + 0.5) * step;\n",
    "        total += 4.0 / (1.0 + x * x);\n",
    "    }\n",
    "    return step * total;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    double result = integrate_pi(100'000'000);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    std::chrono::duration<double> elapsed = end - start;\n",
    "\n",
    "    std::cout << \"Result: \" << std::fixed << std::setprecision(12) << result << std::endl;\n",
    "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << elapsed.count() << \" seconds\" << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592653590\n",
      "Execution Time: 0.118013 seconds\n"
     ]
    }
   ],
   "source": [
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized_kimi optimized_kimi.cpp\n",
    "!./optimized_kimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a05b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592653590\n",
      "Execution Time: 6.972198 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ddedf",
   "metadata": {},
   "source": [
    "### üìà Experiment 1 Results: Kimi Dev 72B Performance\n",
    "\n",
    "#### **‚ö° Performance Analysis**\n",
    "\n",
    "| **Metric** | **Python** | **C++ (Kimi)** | **Improvement** |\n",
    "|------------|------------|----------------|-----------------|\n",
    "| **Execution Time** | 6.97 seconds | 0.118 seconds | **59.1x faster** |\n",
    "| **Result Accuracy** | 3.141592653590 | 3.141592653590 | ‚úÖ **Perfect match** |\n",
    "| **Code Quality** | - | High-performance C++17 | ‚úÖ **Optimized** |\n",
    "\n",
    "#### **üîç Key Observations**\n",
    "\n",
    "**‚ú® Strengths:**\n",
    "- **Exceptional Performance**: Nearly 60x speedup exceeds our 50x target\n",
    "- **Perfect Accuracy**: Identical numerical results demonstrate precision handling\n",
    "- **Code Quality**: Clean, well-structured C++ with proper includes and timing\n",
    "- **Thinking Process**: Model showed detailed reasoning (visible in output)\n",
    "\n",
    "**üõ†Ô∏è Technical Implementation:**\n",
    "- Used `double` precision for numerical stability\n",
    "- Proper C++17 chrono for accurate timing\n",
    "- Optimized loop structure with pre-increment\n",
    "- Correct compiler optimization flags (`-O3`, `-march=armv8.3-a`)\n",
    "\n",
    "**üéØ Verdict**: Kimi Dev 72B demonstrates excellent mathematical reasoning and C++ optimization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdb89400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```cpp\n",
      "#include <iostream>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "double integrate_pi(int iterations) {\n",
      "    double step = 1.0 / iterations;\n",
      "    double total = 0.0;\n",
      "    \n",
      "    for (int i = 0; i < iterations; ++i) {\n",
      "        double x = (i + 0.5) * step;\n",
      "        total += 4.0 / (1.0 + x * x);\n",
      "    }\n",
      "    \n",
      "    return step * total;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start_time = std::chrono::high_resolution_clock::now();\n",
      "    double result = integrate_pi(100000000);\n",
      "    auto end_time = std::chrono::high_resolution_clock::now();\n",
      "    \n",
      "    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);\n",
      "    \n",
      "    std::cout << std::fixed << std::setprecision(12);\n",
      "    std::cout << \"Result: \" << result << std::endl;\n",
      "    \n",
      "    std::cout << std::fixed << std::setprecision(6);\n",
      "    std::cout << \"Execution Time: \" << duration.count() / 1000000.0 << \" seconds\" << std::endl;\n",
      "    \n",
      "    return 0;\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "optimize_qwen(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674e21a",
   "metadata": {},
   "source": [
    "First think that you notice instantly is generation time. Qwen done this in **4.8 SEC**! Style is a little bit different but overall both results actualy same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f3bdfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592653590\n",
      "Execution Time: 0.104924 seconds\n"
     ]
    }
   ],
   "source": [
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized_qwen optimized_qwen.cpp\n",
    "!./optimized_qwen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfd946",
   "metadata": {},
   "source": [
    "## üìä Experiment 1: Complete Results & Analysis\n",
    "\n",
    "### üèÜ Final Performance Comparison\n",
    "\n",
    "| **Metric** | **Python Baseline** | **Kimi Dev 72B** | **Qwen3 Coder** | **Winner** |\n",
    "|------------|---------------------|-------------------|------------------|------------|\n",
    "| **Execution Time** | ~7.0 seconds | 0.118 seconds | 0.105 seconds | ü•á **Qwen3** |\n",
    "| **Speedup Factor** | 1x | **59.3x** | **66.7x** | ü•á **Qwen3** |\n",
    "| **Result Accuracy** | 3.141592653590 | 3.141592653590 ‚úÖ | 3.141592653590 ‚úÖ | ü§ù **Tie** |\n",
    "| **Generation Time** | - | ~15-20 seconds | **4.8 seconds** | ü•á **Qwen3** |\n",
    "| **Code Quality** | - | Excellent | Excellent | ü§ù **Tie** |\n",
    "\n",
    "### üéØ Key Findings\n",
    "\n",
    "#### **üöÄ Performance Excellence**\n",
    "- Both models achieved **exceptional performance gains** (59-67x speedup)\n",
    "- **Qwen3 Coder edges out** with slightly better execution time (0.105s vs 0.118s)\n",
    "- Both far exceeded our **50x speedup target**\n",
    "\n",
    "#### **‚ö° Generation Speed**\n",
    "- **Qwen3 Coder**: **4x faster generation** (4.8s vs ~15-20s)\n",
    "- Critical for production pipelines where conversion time matters\n",
    "- Kimi's thinking process adds value but impacts speed\n",
    "\n",
    "#### **üî¨ Code Analysis**\n",
    "\n",
    "**Similarities:**\n",
    "- Both use `double` precision for numerical stability\n",
    "- Proper C++17 chrono for timing\n",
    "- Identical algorithmic approach\n",
    "- Clean, professional code structure\n",
    "\n",
    "**Differences:**\n",
    "- **Qwen3**: More concise, direct implementation\n",
    "- **Kimi**: More verbose with detailed thinking process wich can be interesting in harder tasks\n",
    "\n",
    "### üìà Statistical Summary\n",
    "\n",
    "```\n",
    "Performance Improvement Over Python:\n",
    "‚îú‚îÄ‚îÄ Kimi Dev 72B:    5,930% faster\n",
    "‚îú‚îÄ‚îÄ Qwen3 Coder:     6,670% faster\n",
    "‚îî‚îÄ‚îÄ Average:         6,300% faster\n",
    "\n",
    "Generation Efficiency:\n",
    "‚îú‚îÄ‚îÄ Qwen3 Coder:     4.8 seconds\n",
    "‚îú‚îÄ‚îÄ Kimi Dev 72B:    ~17.5 seconds (estimated)\n",
    "‚îî‚îÄ‚îÄ Difference:      73% faster generation\n",
    "```\n",
    "\n",
    "### üèÖ Conclusions\n",
    "\n",
    "#### **ü•á Overall Winner: Qwen3 Coder**\n",
    "**Reasons:**\n",
    "1. **Superior Performance**: 12% faster execution\n",
    "2. **Rapid Generation**: 4x faster model response\n",
    "3. **Production Ready**: Optimal for automated pipelines\n",
    "4. **Identical Accuracy**: Perfect mathematical precision\n",
    "\n",
    "#### **ü•à Strong Second: Kimi Dev 72B**\n",
    "**Strengths:**\n",
    "1. **Detailed Reasoning**: Valuable thinking process insights\n",
    "2. **Excellent Performance**: Still achieved 59x speedup\n",
    "3. **Educational Value**: Great for understanding optimization approaches\n",
    "\n",
    "### üî¨ Technical Insights\n",
    "\n",
    "Both models demonstrated:\n",
    "- ‚úÖ **Perfect algorithmic understanding**\n",
    "- ‚úÖ **Optimal C++ optimization techniques**\n",
    "- ‚úÖ **Proper numerical precision handling**\n",
    "- ‚úÖ **Professional code structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77792df6",
   "metadata": {},
   "source": [
    "## Experiment 2: Max sub array sum\n",
    "\n",
    "In this task given an array of random numbers (positives and negatives) and the task is to find maximal sub array sum.\n",
    "In this task we will not generate random numbers using python.random but instead provide implementation of simple linear congurantial generator (lcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b51ce454",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sub_array_sum = \"\"\"# Be careful to support large number sizes\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f99ff3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Maximum Subarray Sum (20 runs): 10980\n",
      "Execution Time: 41.841283 seconds\n"
     ]
    }
   ],
   "source": [
    "python_result = exec(max_sub_array_sum)\n",
    "python_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a657679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚óÅthink‚ñ∑Okay, let's tackle this problem. The user wants to rewrite the given Python code in C++ to make it as fast as possible while ensuring identical output. The key parts are the LCG (Linear Congruential Generator), the max_subarray_sum function using Kadane's algorithm, and the total_max_subarray_sum which runs 20 iterations.\n",
      "\n",
      "First, I need to implement the LCG in C++. The Python version uses generator functions with yield, but in C++, we can use a class or a function that keeps the state. Since the LCG is called multiple times, a class might be better. The LCG parameters (a, c, m) are given, and the seed is initialized. The calculation is (a * value + c) % m. In C++, we need to handle the 32-bit modulus correctly. Using unsigned int might help here, but since m is 2^32, maybe using a 64-bit type to avoid overflow. Wait, m is 2^32, so value is in [0, 2^32 -1]. So using a uint32_t for value would work. But in the calculation a * value could overflow, so perhaps we need to use a 64-bit type for the multiplication. Let me check: a is 1664525, which is about 1.6e6. Multiplying by 2^32 (which is the maximum value) would be 1.6e6 * 4e9 = 6.4e15, which is within 64-bit range. So using a uint64_t for intermediate calculations and then taking modulo m (2^32) would give the correct result. So maybe the LCG can be implemented as a function that takes a seed and returns the next value.\n",
      "\n",
      "Wait, but in the Python code, the LCG is a generator that keeps its state. So in C++, we can create a class that holds the current value and updates it each time next() is called. Alternatively, use a function that takes the previous value and returns the next. But since the Python code uses next(lcg_gen), perhaps we can create an LCG class with a method to get the next value.\n",
      "\n",
      "But maybe in C++, using a function that takes the current seed and returns the next value. Then, each time we need the next number, we pass the current seed and it calculates the next. However, in the Python code, the LCG generator is created once and then next is called multiple times. So in C++, perhaps we can create a struct or class that holds the current seed and has a method to advance it. Let's see.\n",
      "\n",
      "So the LCG part would be something like:\n",
      "\n",
      "struct LCG {\n",
      "    uint32_t seed;\n",
      "    static const uint32_t a = 1664525;\n",
      "    static const uint32_t c = 1013904223;\n",
      "    static const uint64_t m = 1ULL << 32;\n",
      "    LCG(uint32_t s) : seed(s) {}\n",
      "    uint32_t next() {\n",
      "        uint64_t temp = (uint64_t)a * seed + c;\n",
      "        seed = temp % m;\n",
      "        return seed;\n",
      "    }\n",
      "};\n",
      "\n",
      "But since m is 2^32, modulo m is equivalent to taking the lower 32 bits. So temp is a 64-bit integer, a * seed is 64-bit, adding c (which is 32-bit). Then, temp % m would be temp & 0xFFFFFFFF. Because 2^32 modulo is just masking the lower 32 bits. So perhaps we can optimize that.\n",
      "\n",
      "So the next function would be:\n",
      "\n",
      "seed = ((a * seed + c) & 0xFFFFFFFF);\n",
      "\n",
      "But in C++, using bitwise AND with 0xFFFFFFFF would effectively take modulo 2^32. So the code becomes:\n",
      "\n",
      "uint32_t next() {\n",
      "    uint64_t temp = (uint64_t)a * seed + c;\n",
      "    seed = temp & 0xFFFFFFFF;\n",
      "    return seed;\n",
      "}\n",
      "\n",
      "But wait, a and c are constants. Let's define them as uint32_t. Let's check their values:\n",
      "\n",
      "a = 1664525 ‚Üí fits in 32 bits.\n",
      "\n",
      "c = 1013904223 ‚Üí fits in 32 bits.\n",
      "\n",
      "So when we multiply a (uint32_t) by seed (uint32_t), the product can be up to (2^32 -1)^2, which is about 4e18, which is larger than 32 bits but fits in 64 bits. So using a 64-bit temporary variable is necessary to avoid overflow. Then, adding c (uint32_t) would still be within 64 bits. Then, taking modulo 2^32 (or & 0xFFFFFFFF) gives the correct next seed.\n",
      "\n",
      "So the LCG class would be:\n",
      "\n",
      "class LCG {\n",
      "public:\n",
      "    static const uint32_t a = 1664525;\n",
      "    static const uint32_t c = 1013904223;\n",
      "    static const uint64_t m = 0x100000000ULL;  // 2^32\n",
      "\n",
      "    LCG(uint32_t seed) : value(seed) {}\n",
      "\n",
      "    uint32_t next() {\n",
      "        uint64_t next_val = (static_cast<uint64_t>(a) * value + c) % m;\n",
      "        value = static_cast<uint32_t>(next_val);\n",
      "        return value;\n",
      "    }\n",
      "\n",
      "private:\n",
      "    uint32_t value;\n",
      "};\n",
      "\n",
      "But since m is 2^32, the modulo operation can be replaced with a bitwise AND. So the calculation becomes:\n",
      "\n",
      "next_val = ((static_cast<uint64_t>(a) * value + c) & 0xFFFFFFFFULL);\n",
      "\n",
      "But using the modulo operator would be clearer, but perhaps the compiler optimizes it. Alternatively, use the bitwise AND. Let's use the modulo since m is a constant. Wait, no. If m is 2^32, then x % m is x & (m - 1) if x is a non-negative integer. So x % 0x100000000 is x & 0xFFFFFFFF. Wait, but 0x100000000 is 2^32, so x % (2^32) is x & (2^32 -1) if x is a 64-bit integer. So temp = (a * value + c) which is a 64-bit integer. So:\n",
      "\n",
      "next_val = (a * value + c) % (1ULL << 32);\n",
      "\n",
      "Which is equivalent to:\n",
      "\n",
      "next_val = (a * value + c) & 0xFFFFFFFF;\n",
      "\n",
      "So in code:\n",
      "\n",
      "uint64_t temp = static_cast<uint64_t>(a) * value + c;\n",
      "value = static_cast<uint32_t>(temp & 0xFFFFFFFFULL);\n",
      "\n",
      "So the LCG's next() method would be:\n",
      "\n",
      "return value;\n",
      "\n",
      "So the LCG class is:\n",
      "\n",
      "class LCG {\n",
      "public:\n",
      "    static const uint32_t a = 1664525;\n",
      "    static const uint32_t c = 1013904223;\n",
      "\n",
      "    LCG(uint32_t seed) : value(seed) {}\n",
      "\n",
      "    uint32_t next() {\n",
      "        uint64_t temp = static_cast<uint64_t>(a) * value + c;\n",
      "        value = static_cast<uint32_t>(temp & 0xFFFFFFFF);\n",
      "        return value;\n",
      "    }\n",
      "\n",
      "private:\n",
      "    uint32_t value;\n",
      "};\n",
      "\n",
      "But in C++, we need to include the necessary headers. So we need to include <cstdint> for uint32_t and uint64_t.\n",
      "\n",
      "Next, the max_subarray_sum function. The Python code uses a brute-force approach with nested loops, which is O(n^2). But for n=10000, this would be 100 million operations, which might be slow. The optimal solution is Kadane's algorithm, which is O(n). So the original Python code is using the brute-force approach, but the user might expect the C++ code to use the same approach to ensure identical output. Wait, no. The user's Python code has a bug because the brute-force approach is too slow for large n. Wait, the original Python code is generating n=10000 random numbers and then for each of the 20 seeds, computing the max subarray sum. But in the max_subarray_sum function, it's using a brute-force O(n^2) approach. For n=10000, that's 10000^2 /2 ‚âà 50 million iterations. Doing this 20 times would be 1 billion iterations. That's way too slow. But the user probably expects that in the C++ code, we use Kadane's algorithm (O(n)) instead of the brute-force approach. Because otherwise, even with C++ it would be too slow. So maybe the Python code has a mistake, but the user wants us to reproduce the same output, so even if it's slow? Or perhaps they made a mistake and meant to use Kadane's, but either way, we need to match the Python output.\n",
      "\n",
      "Wait, looking at the Python code: the max_subarray_sum function is using:\n",
      "\n",
      "max_sum = float('-inf')\n",
      "for i in range(n):\n",
      "    current_sum = 0\n",
      "    for j in range(i, n):\n",
      "        current_sum += random_numbers[j]\n",
      "        if current_sum > max_sum:\n",
      "            max_sum = current_sum\n",
      "\n",
      "This is the classic Kadane's algorithm, no? Wait no. Kadane's algorithm is O(n) and does it in one pass. The code here is O(n^2) because for each i, it checks all j >=i. That's not Kadane's. So why would the user do that? Maybe they made a mistake, but if we want to reproduce the same output, we need to implement the same algorithm. So if the Python code uses the O(n^2) approach, then the C++ code must do that as well. However, if the user intended to use Kadane's algorithm but accidentally wrote the O(n^2) version, then fixing the C++ code would lead to a different output. But according to the problem statement, we need to produce identical output. So perhaps the Python code is intended to use the O(n) approach. Let me double-check.\n",
      "\n",
      "Wait, the code in the Python function max_subarray_sum is:\n",
      "\n",
      "max_sum = float('-inf')\n",
      "for i in range(n):\n",
      "    current_sum = 0\n",
      "    for j in range(i, n):\n",
      "        current_sum += random_numbers[j]\n",
      "        if current_sum > max_sum:\n",
      "            max_sum = current_sum\n",
      "\n",
      "This is not Kadane's algorithm. Kadane's algorithm is:\n",
      "\n",
      "max_sum = float('-inf')\n",
      "current_sum = 0\n",
      "for num in random_numbers:\n",
      "    current_sum = max(num, current_sum + num)\n",
      "    max_sum = max(max_sum, current_sum)\n",
      "\n",
      "So the Python code is using a brute-force approach, which for n=10000 would be 10000^2 /2 operations. But that's about 50 million operations. Even in Python, this would be slow. For C++, it would be faster, but 20 * 50 million is 1 billion operations, which might take seconds. However, if we use Kadane's algorithm, it would be O(n), so 20 * 10000 = 200,000 operations. So that's much faster.\n",
      "\n",
      "But the user's Python code is using the O(n^2) method. However, looking at the problem statement, the user says the code should produce identical output. So perhaps the user intended to use Kadane's algorithm but made a mistake. Alternatively, the user might have intended for the code to be correct. But the Python code is using the O(n^2) approach. If we need to reproduce that, then the C++ code should use the same approach. However, if the user's Python code is incorrect and the correct approach is O(n), then maybe that's a mistake. But according to the problem, we need to reimplement the code as given, just faster. So even if the Python code is inefficient, the C++ code should replicate the same logic. But n=10000 and 20 runs would make 20 * (10000^2 /2) = 1,000,000,000 iterations. That's a lot. But with C++ being much faster than Python, maybe it's feasible. However, even then, we need to see. Alternatively, perhaps the user made a mistake and used the O(n) approach, but the code in the problem is not. Wait, the problem's Python code for max_subarray_sum uses the nested loops. So if we need to reproduce the same output, we have to implement the same nested loops. However, that would be too slow for n=10000, even in C++. Let's estimate: 20 * 10000 * 10000 / 2 = 100 million iterations. If each iteration is a few operations, perhaps doable at 1 GHz, which would take 0.1 seconds. But maybe modern processors are faster. Alternatively, if the code is using the correct algorithm (Kadane), then the Python code is wrong. But the problem's code is as given. So the answer depends on whether the user's code uses the correct algorithm or not.\n",
      "\n",
      "Ah, here's the key: The problem says that we need to produce \"identical output\" in the fastest possible time. So perhaps the user made a mistake and the correct approach is to use Kadane's algorithm. Therefore, even though the Python code uses the O(n^2) approach, the intended behavior is to use O(n), and the user's code is wrong. So the C++ code should implement Kadane's algorithm. But how can we know? The problem says \"reimplements Python code in high performance C++\". So if we can improve the algorithm while maintaining the same output, that's better. But how?\n",
      "\n",
      "Wait, perhaps the Python code's nested loops are actually equivalent to Kadane's algorithm. Let's think. Let's take an example array: [1, -2, 3, 4]. The nested loops would check all possible subarrays:\n",
      "\n",
      "For i=0:\n",
      "\n",
      "j=0: sum=1 ‚Üí max_sum=1\n",
      "\n",
      "j=1: sum=1 + (-2) = -1 ‚Üí max_sum remains 1\n",
      "\n",
      "j=2: sum=-1 +3=2 ‚Üí max_sum=2\n",
      "\n",
      "j=3: sum=2+4=6 ‚Üí max_sum=6\n",
      "\n",
      "For i=1:\n",
      "\n",
      "j=1: sum=-2 ‚Üí no change\n",
      "\n",
      "j=2: sum=-2+3=1 ‚Üí max_sum=6\n",
      "\n",
      "j=3: sum=1+4=5 ‚Üí max_sum=6\n",
      "\n",
      "For i=2:\n",
      "\n",
      "j=2: sum=3 ‚Üí max_sum=6\n",
      "\n",
      "j=3: sum=3+4=7 ‚Üí max_sum=7\n",
      "\n",
      "For i=3:\n",
      "\n",
      "j=3: sum=4 ‚Üí max_sum=7\n",
      "\n",
      "So the maximum subarray sum is 7 (subarray [3,4]).\n",
      "\n",
      "Now, using Kadane's algorithm:\n",
      "\n",
      "current_sum=0, max_sum=-inf\n",
      "\n",
      "First num=1:\n",
      "\n",
      "current_sum = max(1, 0+1) =1 ‚Üí max_sum=1\n",
      "\n",
      "Second num=-2:\n",
      "\n",
      "current_sum = max(-2, 1 + -2) = max(-2, -1) ‚Üí current_sum=-1 ‚Üí but max_sum=1 remains.\n",
      "\n",
      "Third num=3:\n",
      "\n",
      "current_sum = max(3, -1 +3)= max(3,2)=3 ‚Üí max_sum=3\n",
      "\n",
      "Fourth num=4:\n",
      "\n",
      "current_sum = max(4,3+4)= max(4,7)=7 ‚Üí max_sum=7\n",
      "\n",
      "So both approaches give the same result. But in the nested loops, we are checking all possible subarrays. In Kadane's, we are keeping track of the best subarray ending at each position. The result is the same, but the O(n^2) approach is much slower. However, if the user's Python code uses the O(n^2) approach, the C++ code must replicate that, even if it's slower. But that's not efficient. So maybe the user made a mistake, and the intended code uses Kadane's algorithm. Looking at the Python code:\n",
      "\n",
      "In the max_subarray_sum function:\n",
      "\n",
      "max_sum = float('-inf')\n",
      "for i in range(n):\n",
      "    current_sum = 0\n",
      "    for j in range(i, n):\n",
      "        current_sum += random_numbers[j]\n",
      "        if current_sum > max_sum:\n",
      "            max_sum = current_sum\n",
      "\n",
      "This is actually equivalent to Kadane's algorithm. Wait, no. Because in the inner loop, for each i, it's building all suffixes starting at i and accumulating. But Kadane's does this in a single pass. For example, in the nested loop approach, the current_sum starts at 0 for each i, and adds subsequent elements. So for each i, it checks all subarrays starting at i. But Kadane's algorithm is dynamic programming where each current_sum is the maximum of the current element alone or the sum including the previous subarray. So the nested loops approach is O(n^2), while Kadane's is O(n). The problem is that the user's Python code uses the brute-force approach, which is slow. But if we convert that to Kadane's in C++, then the output would be the same but faster. However, the user's Python code is incorrect (in terms of efficiency) but the problem requires that the C++ code produces identical output. Wait, but the output is the same whether we use O(n^2) or O(n). So if the user intended to use the correct algorithm (Kadane's) but the Python code uses O(n^2), then the C++ code should use the O(n) approach. But how do we know? The problem states that the C++ code should produce \"identical output\". So if the Python code's algorithm is correct, the C++ code should implement the same algorithm but faster. However, if the Python code's algorithm is wrong, then the C++ code may need to implement the correct one. But the problem as given shows the Python code, which uses the nested loops. Therefore, to reproduce the same output (even if the code is slow), the C++ code should implement the same nested loops. But for n=10000, this would result in a very slow program. However, the user mentioned \"M1 Mac\" which is known for having good performance. Maybe in C++, even with O(n^2), it's manageable.\n",
      "\n",
      "But perhaps there's a misunderstanding here. Let's check the problem again. The user says: \"Rewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time.\" So the goal is to produce the same output but as quickly as possible. So if the Python code's algorithm is correct (i.e., produces the correct max subarray sum), but is inefficient, then the C++ code can use a more efficient algorithm (like Kadane's) to achieve the same result faster. Because the output would be the same. The key is that the output (the value) is the same, not the algorithm used. So even if the Python code uses a brute-force O(n^2) approach, the C++ code can use Kadane's O(n) approach to get the same result in less time. So that's the way to go.\n",
      "\n",
      "So the C++ code for max_subarray_sum should use Kadane's algorithm. Let's implement that.\n",
      "\n",
      "The max_subarray_sum function would be:\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& numbers) {\n",
      "    int max_sum = std::numeric_limits<int>::min();\n",
      "    int current_sum = 0;\n",
      "    for (int num : numbers) {\n",
      "        current_sum = std::max(num, current_sum + num);\n",
      "        max_sum = std::max(max_sum, current_sum);\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "But first, the random_numbers are generated as in the Python code: each number is (next(lcg_gen) % (max_val - min_val + 1)) + min_val. So for example, if min_val = -10 and max_val = 10, then max_val - min_val +1 is 21. So the mod is 21, then add min_val. So the random numbers can range from -10 to 10 (inclusive). Therefore, the numbers are 32-bit integers, but some could be negative. So in C++, we need to use signed integers. But in the LCG, the numbers are generated as uint32_t. So when we take next(lcg) % (max_val - min_val +1), which is 21, then add min_val (-10), we need to make sure that the result is a signed integer. For example, uint32_t mod 21 gives a value between 0 and 20. Adding -10 would give numbers between -10 and 10. So in C++, we need to cast the uint32_t to an int32_t before performing the modulo and addition. Because otherwise, taking modulo with a negative result could lead to unexpected behavior. So the code to generate each random number would be:\n",
      "\n",
      "int num = (static_cast<int>(next_lcg_value) % (max_val - min_val + 1)) + min_val;\n",
      "\n",
      "But wait, when we cast a uint32_t to int, if the integer is larger than INT_MAX (which is 2147483647), it would overflow. However, the LCG is generating values up to 2^32 -1 (4294967295), which is larger than INT_MAX. So casting to int would cause overflow. Therefore, we need to handle large integers. But since in the Python code, the numbers are generated as (next(lcg_gen) % (max_val - min_val +1)) + min_val. So the next(lcg_gen) is a 32-bit value. So when we compute next_lcg_gen % (max_val - min_val +1), which is at most 21, then add min_val (-10), the result is between -10 and 10. So the division/modulo can be done as unsigned, but the addition leads to signed. So perhaps in C++, we need to cast the uint32_t to an int64_t to avoid overflow, then perform the modulo and addition. For example:\n",
      "\n",
      "uint32_t next_val = lcg.next();\n",
      "int num = (static_cast<int64_t>(next_val) % (max_val - min_val + 1)) + min_val;\n",
      "\n",
      "But if max_val - min_val +1 is 21, then (next_val %21) is between 0 and 20, then adding min_val (-10) gives numbers between -10 and 10. So num is between -10 and 10, which can be stored as an int (int32_t or int64_t). But since the sum can be negative, and the numbers are signed, we need to use signed integers in the Kadane's algorithm.\n",
      "\n",
      "So the random_numbers are generated using the LCG, then each element is:\n",
      "\n",
      "num = (lcg_value % (max_val - min_val +1)) + min_val.\n",
      "\n",
      "But in C++, the % operator for negative numbers is different from Python. Wait, if lcg_value is a uint32_t, then (lcg_value % (max_val - min_val +1)) is a non-negative integer. Then adding min_val (negative) would result in a negative number. But when we cast the uint32_t to a signed type, we need to be careful. Wait, but (lcg_value) is between 0 and 2^32 -1, and (max_val - min_val +1) is 21. So (lcg_value %21) is between 0 and 20. Adding min_val (-10) gives between 0-10 and -10 to 20-10, i.e., -10 to 10. So the resulting number is in [-10,10]. So when generating the random_numbers array, each element should be an int, but since the numbers can be negative, we can use int32_t.\n",
      "\n",
      "So the code to generate the random numbers would be:\n",
      "\n",
      "std::vector<int> random_numbers(n);\n",
      "LCG lcg(seed);\n",
      "for (int i = 0; i < n; ++i) {\n",
      "    uint32_t next_val = lcg.next();\n",
      "    int num = (static_cast<int>(next_val) % (max_val - min_val + 1)) + min_val;\n",
      "    random_numbers[i] = num;\n",
      "}\n",
      "\n",
      "But wait, when we cast next_val (uint32_t) to int, if next_val is larger than 0x7FFFFFFF, then the int would overflow. This is a problem. So to correctly compute (next_val % (max_val - min_val +1)), we should perform the modulo operation as unsigned, then cast to int and add min_val.\n",
      "\n",
      "So the code should be:\n",
      "\n",
      "uint32_t next_val = lcg.next();\n",
      "uint32_t mod_val = max_val - min_val + 1;\n",
      "uint32_t remainder = next_val % mod_val;\n",
      "int num = static_cast<int>(remainder) + min_val;\n",
      "\n",
      "But since remainder is between 0 and mod_val-1, adding min_val would give numbers between min_val and max_val. So this is correct. Therefore, the code for generating random_numbers is:\n",
      "\n",
      "std::vector<int> random_numbers(n);\n",
      "LCG lcg_instance(seed);\n",
      "for (int i = 0; i < n; ++i) {\n",
      "    uint32_t next_val = lcg_instance.next();\n",
      "    uint32_t range = max_val - min_val + 1;\n",
      "    uint32_t mod = next_val % range;\n",
      "    int num = static_cast<int>(mod) + min_val;\n",
      "    random_numbers[i] = num;\n",
      "}\n",
      "\n",
      "Now, the max_subarray_sum function. As discussed, using Kadane's algorithm. So:\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& nums) {\n",
      "    if (nums.empty()) return 0; // or perhaps handle as needed\n",
      "    int max_sum = nums[0];\n",
      "    int current_sum = nums[0];\n",
      "    for (size_t i = 1; i < nums.size(); ++i) {\n",
      "        current_sum = std::max(nums[i], current_sum + nums[i]);\n",
      "        max_sum = std::max(max_sum, current_sum);\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "Wait, but in the Python code, the initial max_sum is float('-inf'), which is the smallest possible value. In C++, we can set it to the minimum possible integer, but if the array contains all negative numbers, this would capture the maximum. However, according to Kadane's algorithm, the max_sum is initialized to the first element, and current_sum starts with the first element. But if the first element is very negative, perhaps the code should initialize to the first element. But perhaps the code should be:\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& nums) {\n",
      "    int max_sum = nums[0];\n",
      "    int current_sum = nums[0];\n",
      "    for (size_t i = 1; i < nums.size(); ++i) {\n",
      "        current_sum = nums[i] + std::max(0, current_sum);\n",
      "        if (current_sum > max_sum) {\n",
      "            max_sum = current_sum;\n",
      "        }\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "Wait, no. The standard Kadane's algorithm is:\n",
      "\n",
      "max_sum = current_sum = nums[0]\n",
      "for i from 1 to n-1:\n",
      "    current_sum = max(nums[i], current_sum + nums[i])\n",
      "    max_sum = max(max_sum, current_sum)\n",
      "\n",
      "So in C++ code:\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& nums) {\n",
      "    int max_sum = nums[0];\n",
      "    int current_sum = nums[0];\n",
      "    for (size_t i = 1; i < nums.size(); ++i) {\n",
      "        current_sum = std::max(nums[i], current_sum + nums[i]);\n",
      "        max_sum = std::max(max_sum, current_sum);\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "But if the array is empty, this code would be invalid. However, in the Python code, the array is generated with n elements (n=10000), so it's not empty.\n",
      "\n",
      "So, putting it all together.\n",
      "\n",
      "The total_max_subarray_sum function in Python does:\n",
      "\n",
      "for _ in range(20):\n",
      "    seed = next(lcg_gen)\n",
      "    total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
      "\n",
      "So in C++, we need to create an LCG for the initial seed, generate 20 seeds, and for each, generate a random_numbers array and compute max_subarray_sum.\n",
      "\n",
      "Putting it all together:\n",
      "\n",
      "We need to implement:\n",
      "\n",
      "1. The LCG generator.\n",
      "\n",
      "2. Generate 20 seeds from the initial LCG.\n",
      "\n",
      "3. For each seed, generate the random_numbers array, compute max_subarray_sum, and sum them up.\n",
      "\n",
      "Now, the code.\n",
      "\n",
      "First, include necessary headers.\n",
      "\n",
      "Need for:\n",
      "\n",
      "- LCG: uint32_t, so #include <cstdint>\n",
      "\n",
      "- Vector for random_numbers: #include <vector>\n",
      "\n",
      "- std::max: #include <algorithm>\n",
      "\n",
      "- Timer: #include <chrono>\n",
      "\n",
      "- Output: #include <iostream>\n",
      "\n",
      "- Formatting: #include <iomanip>\n",
      "\n",
      "So the main code would be:\n",
      "\n",
      "#include <iostream>\n",
      "#include <vector>\n",
      "#include <cstdint>\n",
      "#include <algorithm>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "class LCG {\n",
      "public:\n",
      "    static const uint32_t a = 1664525;\n",
      "    static const uint32_t c = 1013904223;\n",
      "    static const uint64_t m = 0x100000000ULL; // 2^32\n",
      "\n",
      "    LCG(uint32_t seed) : value(seed) {}\n",
      "\n",
      "    uint32_t next() {\n",
      "        uint64_t temp = static_cast<uint64_t>(a) * value + c;\n",
      "        value = static_cast<uint32_t>(temp % m);\n",
      "        return value;\n",
      "    }\n",
      "\n",
      "private:\n",
      "    uint32_t value;\n",
      "};\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& numbers) {\n",
      "    int max_sum = numbers[0];\n",
      "    int current_sum = numbers[0];\n",
      "    for (size_t i = 1; i < numbers.size(); ++i) {\n",
      "        current_sum = std::max(numbers[i], current_sum + numbers[i]);\n",
      "        max_sum = std::max(max_sum, current_sum);\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "int total_max_subarray_sum(int n, uint32_t initial_seed, int min_val, int max_val) {\n",
      "    int total_sum = 0;\n",
      "    LCG lcg_gen(initial_seed);\n",
      "    for (int _ = 0; _ < 20; ++_) {\n",
      "        uint32_t seed = lcg_gen.next();\n",
      "        std::vector<int> random_numbers(n);\n",
      "        LCG lcg_instance(seed);\n",
      "        for (int i = 0; i < n; ++i) {\n",
      "            uint32_t next_val = lcg_instance.next();\n",
      "            uint32_t range = max_val - min_val + 1;\n",
      "            uint32_t mod = next_val % range;\n",
      "            int num = static_cast<int>(mod) + min_val;\n",
      "            random_numbers[i] = num;\n",
      "        }\n",
      "        total_sum += max_subarray_sum(random_numbers);\n",
      "    }\n",
      "    return total_sum;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    const int n = 10000;\n",
      "    const uint32_t initial_seed = 42;\n",
      "    const int min_val = -10;\n",
      "    const int max_val = 10;\n",
      "\n",
      "    auto start = std::chrono::high_resolution_clock::now();\n",
      "    long long result = total_max_subarray_sum(n, initial_seed, min_val, max_val);\n",
      "    auto end = std::chrono::high_resolution_clock::now();\n",
      "\n",
      "    std::chrono::duration<double> duration = end - start;\n",
      "\n",
      "    std::cout << \"Total Maximum Subarray Sum (20 runs): \" << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << duration.count() << \" seconds\" << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "Wait, but in the Python code, the parameters are passed as:\n",
      "\n",
      "n = 10000\n",
      "initial_seed = 42\n",
      "min_val = -10\n",
      "max_val = 10\n",
      "\n",
      "In C++, the initial_seed is 42, which is an integer. So when creating the LCG with initial_seed, it's cast to uint32_t.\n",
      "\n",
      "The code for total_max_subarray_sum creates an LCG from the initial_seed, then for 20 times, generates the next seed, creates a new LCG from that seed, generates the random_numbers array, computes the max_subarray_sum, and adds to total_sum.\n",
      "\n",
      "But in the Python code, the total_max_subarray_sum creates an LCG_gen from the initial_seed, then for each run, gets the next seed from that LCG_gen. So in C++, the code should create an LCG instance with initial_seed, and for each of 20 iterations, call next() to get the seed. Then, for each seed, generate the random_numbers and compute the max.\n",
      "\n",
      "But in the code above, the for loop is int _ = 0 to 19, and each time, seed = lcg_gen.next(). Then, create a new LCG instance with that seed. Then generate the numbers, etc.\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Now, the LCG's next() function is correct. Let's check:\n",
      "\n",
      "The Python code's LCG is:\n",
      "\n",
      "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
      "    value = seed\n",
      "    while True:\n",
      "        value = (a * value + c) % m\n",
      "        yield value\n",
      "\n",
      "In C++, the next() method does:\n",
      "\n",
      "next_val = (a * value + c) % m\n",
      "\n",
      "But in the C++ code, a and c are defined as uint32_t, but when multiplied, they are cast to uint64_t. Then added, and modulo m (2^32) is taken. So the calculation is correct.\n",
      "\n",
      "The random_numbers are generated as:\n",
      "\n",
      "next_val = lcg_instance.next()\n",
      "mod = next_val % (max_val - min_val +1)\n",
      "num = mod + min_val\n",
      "\n",
      "In C++, this is done as:\n",
      "\n",
      "range = max_val - min_val + 1;\n",
      "mod = next_val % range;\n",
      "num = static_cast<int>(mod) + min_val;\n",
      "\n",
      "But since next_val is uint32_t, range is an int. But if range is larger than 2^32, this could be a problem. But in the given parameters, max_val is 10 and min_val is -10. So max_val - min_val +1 is 21. So 21 is safe.\n",
      "\n",
      "Now, the code uses Kadane's algorithm, which is O(n), so for each of the 20 runs, the time is O(n), leading to O(20n) time. For n=10000, that's 200,000 operations. This should be very fast in C++, even with looping 20 times.\n",
      "\n",
      "Now, the timing. The code uses std::chrono::high_resolution_clock to measure time. The duration is converted to seconds. The output uses std::fixed and std::setprecision(6) to format the time.\n",
      "\n",
      "Finally, the code should produce the same result as the Python code, but faster. The key is to ensure that the LCG generates the same sequence of values as the Python code. Since Python's integer division uses a modulo that handles negatives differently, but in this case, the next_val is always non-negative (since it's generated by the LCG as a uint32_t). So the modulo operation with a positive number is safe.\n",
      "\n",
      "Thus, the C++ code should produce the same result as the Python code, but much faster.\n",
      "‚óÅ/think‚ñ∑\n",
      "\n",
      "```cpp\n",
      "#include <iostream>\n",
      "#include <vector>\n",
      "#include <cstdint>\n",
      "#include <algorithm>\n",
      "#include <chrono>\n",
      "#include <iomanip>\n",
      "\n",
      "class LCG {\n",
      "public:\n",
      "    static const uint32_t a = 1664525;\n",
      "    static const uint32_t c = 1013904223;\n",
      "    static const uint64_t m = 0x100000000ULL; // 2^32\n",
      "\n",
      "    LCG(uint32_t seed) : value(seed) {}\n",
      "\n",
      "    uint32_t next() {\n",
      "        uint64_t temp = static_cast<uint64_t>(a) * value + c;\n",
      "        value = static_cast<uint32_t>(temp % m);\n",
      "        return value;\n",
      "    }\n",
      "\n",
      "private:\n",
      "    uint32_t value;\n",
      "};\n",
      "\n",
      "int max_subarray_sum(const std::vector<int>& numbers) {\n",
      "    int max_sum = numbers[0];\n",
      "    int current_sum = numbers[0];\n",
      "    for (size_t i = 1; i < numbers.size(); ++i) {\n",
      "        current_sum = std::max(numbers[i], current_sum + numbers[i]);\n",
      "        max_sum = std::max(max_sum, current_sum);\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "int total_max_subarray_sum(int n, uint32_t initial_seed, int min_val, int max_val) {\n",
      "    int total_sum = 0;\n",
      "    LCG lcg_gen(initial_seed);\n",
      "    for (int _ = 0; _ < 20; ++_) {\n",
      "        uint32_t seed = lcg_gen.next();\n",
      "        std::vector<int> random_numbers(n);\n",
      "        LCG lcg_instance(seed);\n",
      "        for (int i = 0; i < n; ++i) {\n",
      "            uint32_t next_val = lcg_instance.next();\n",
      "            uint32_t range = max_val - min_val + 1;\n",
      "            uint32_t mod = next_val % range;\n",
      "            int num = static_cast<int>(mod) + min_val;\n",
      "            random_numbers[i] = num;\n",
      "        }\n",
      "        total_sum += max_subarray_sum(random_numbers);\n",
      "    }\n",
      "    return total_sum;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    const int n = 10000;\n",
      "    const uint32_t initial_seed = 42;\n",
      "    const int min_val = -10;\n",
      "    const int max_val = 10;\n",
      "\n",
      "    auto start = std::chrono::high_resolution_clock::now();\n",
      "    long long result = total_max_subarray_sum(n, initial_seed, min_val, max_val);\n",
      "    auto end = std::chrono::high_resolution_clock::now();\n",
      "\n",
      "    std::chrono::duration<double> duration = end - start;\n",
      "\n",
      "    std::cout << \"Total Maximum Subarray Sum (20 runs): \" << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << std::fixed << std::setprecision(6) << duration.count() << \" seconds\" << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "optimize_kimi(max_sub_array_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf074e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Maximum Subarray Sum (20 runs): 10980\n",
      "Execution Time: 0.000485 seconds\n"
     ]
    }
   ],
   "source": [
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized_kimi optimized_kimi.cpp\n",
    "!./optimized_kimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_qwen(max_sub_array_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bdb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized_qwen optimized_qwen.cpp\n",
    "!./optimized_qwen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f005ca6",
   "metadata": {},
   "source": [
    "## UI\n",
    "\n",
    "Let's also add Gradio UI. \n",
    "\n",
    "<span style=\"color:red\">Be carefull, never use \"share=True\" for this project, this will create security vulnarabillity for you</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ae04e",
   "metadata": {},
   "source": [
    "~~We can notice that SWE-bench leaderboard contain one more interesting candidate. It is **Gemini 2.5 Pro** with 53.6%~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "870f21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Provider(enum.Enum):\n",
    "    OPEN_AI = \"OpenAI\"\n",
    "    # GOOGLE = \"Google\"\n",
    "\n",
    "@dataclass\n",
    "class ModelInfo:\n",
    "    model_name: str\n",
    "    model_id: str\n",
    "    client: Provider\n",
    "\n",
    "AVAILABLE_MODELS = [\n",
    "    ModelInfo(model_name=\"Kimi K2\", model_id=MODEL_KIMI_K2, client=Provider.OPEN_AI),\n",
    "    ModelInfo(model_name=\"Qwen 3 Coder\", model_id=MODEL_QWEN_3_CODER, client=Provider.OPEN_AI),\n",
    "    # ModelInfo(model_name=\"Gemini 2 Flash\", model_id=MODEL_QWEN_3_CODER, client=Provider.GOOGLE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93447eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model_open_ai_client(model, python):    \n",
    "    stream = or_client.chat.completions.create(model=model, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply\n",
    "\n",
    "def stream_model(model_info, python):\n",
    "    if model_info.client == Provider.OPEN_AI:\n",
    "        return stream_model_open_ai_client(model_info.model_id, python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown client\")\n",
    "\n",
    "def trim_result(result):\n",
    "    result = re.sub(r'‚óÅthink‚ñ∑.*?‚óÅ/think‚ñ∑\\n\\n', '', result, flags=re.DOTALL)\n",
    "    result = result.replace('```cpp\\n','').replace('```','')\n",
    "    return result\n",
    "\n",
    "def optimize(python, model):\n",
    "    if model==\"Kimi K2\":\n",
    "        model_info = next(model for model in AVAILABLE_MODELS if model.model_name == \"Kimi K2\")\n",
    "        result = stream_model(model_info, python)\n",
    "    elif model==\"Qwen 3 Coder\":\n",
    "        model_info = next(model for model in AVAILABLE_MODELS if model.model_name == \"Qwen 3 Coder\")\n",
    "        result = stream_model(model_info, python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    # Stream all output to thinking first\n",
    "    final_result = \"\"\n",
    "    for stream_buffer in result:\n",
    "        final_result = stream_buffer\n",
    "        yield stream_buffer, \"\"  \n",
    "    \n",
    "    # When streaming is complete, trim result and show in cpp\n",
    "    trimmed_cpp = trim_result(final_result)\n",
    "    yield final_result, trimmed_cpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [model.model_name for model in AVAILABLE_MODELS]\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", lines=15, value=max_sub_array_sum)\n",
    "        with gr.Column():\n",
    "            thinking = gr.Textbox(label=\"Thinking:\", lines=5)\n",
    "            cpp = gr.Textbox(label=\"C++ code:\", lines=10)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown(available_models, label=\"Select model\", value=\"Kimi K2\")\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "\n",
    "    convert.click(optimize, inputs=[python, model], outputs=[thinking, cpp])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
